{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed018f19-70ad-4733-bccb-4328acccd7c2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Lab Exercise:\n",
    "## Washingtons and Marthas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75c0dcd0-4e24-4c8a-b338-0897d4738c69",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "-sandbox\n",
    "##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Instructions\n",
    "\n",
    "This data was captured in the August before the 2016 US presidential election.\n",
    "\n",
    "As a result, articles about the candidates were very popular.\n",
    "\n",
    "For this exercise, you will...\n",
    "0. Filter the result to the **en** Wikipedia project.\n",
    "0. Find all the articles where the name of the article **ends** with **_Washington** (presumably \"George Washington\", \"Martha Washington\", etc)\n",
    "0. Return all records as an array to the Driver.\n",
    "0. Assign your array of Washingtons (the return value of your action) to the variable `washingtons`.\n",
    "0. Calculate the sum of requests for the Washingtons and assign it to the variable `totalWashingtons`. <br/>\n",
    "<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** We've not yet covered `DataFrame` aggregation techniques, so for this exercise use the array of records you have just obtained.\n",
    "\n",
    "** Bonus **\n",
    "\n",
    "Repeat the exercise for the Marthas\n",
    "0. Filter the result to the **en** Wikipedia project.\n",
    "0. Find all the articles where the name of the article **starts** with **Martha_** (presumably \"Martha Washington\", \"Martha Graham\", etc)\n",
    "0. Return all records as an array to the Driver.\n",
    "0. Assign your array of Marthas (the return value of your action) to the variable `marthas`.\n",
    "0. Calculate the sum of requests for the Marthas and assign it to the variable `totalMarthas`.<br/>\n",
    "<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** We've not yet covered `DataFrame` aggregation techniques, so for this exercise use the array of records you have just obtained.\n",
    "0. But you cannot do it the same way twice:\n",
    "   * In the filter, don't use the same conditional method as the one used for the Washingtons.\n",
    "   * Don't use the same action as used for the Washingtons.\n",
    "\n",
    "**Testing**\n",
    "\n",
    "Run the last cell to verify that your results are correct.\n",
    "\n",
    "**Hints**\n",
    "* <img alt=\"Caution\" title=\"Caution\" style=\"vertical-align: text-bottom; position: relative; height:1.3em; top:0.0em\" src=\"https://files.training.databricks.com/static/images/icon-warning.svg\"/> Make sure to include the underscore in the condition.\n",
    "* The actions we've explored for extracting data include:\n",
    "  * `first()`\n",
    "  * `collect()`\n",
    "  * `head()`\n",
    "  * `take(n)`\n",
    "* The conditional methods used with a `filter(..)` include:\n",
    "  * equals\n",
    "  * not-equals\n",
    "  * starts-with\n",
    "  * and there are others - remember, the `DataFrames` API is built upon an SQL engine.\n",
    "* There shouldn't be more than 1000 records for either the Washingtons or the Marthas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c72fa0f-624a-4e2a-bbad-07a05d5c75c6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Getting Started\n",
    "\n",
    "Run the following cell to configure our \"classroom.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39f48ead-8aac-4cca-a4e1-865838c4329b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Initialized classroom variables & functions..."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Initialized classroom variables & functions...",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Mounted datasets to <b>/mnt/training</b> from <b>wasbs://training@dbtrainwesteurope.blob.core.windows.net/<b>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Mounted datasets to <b>/mnt/training</b> from <b>wasbs://training@dbtrainwesteurope.blob.core.windows.net/<b>",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run \"./Includes/Classroom-Setup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7cb98fb-7066-42ca-81d7-026c9b8789ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/training/ has been unmounted.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Created user-specific database"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Created user-specific database",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Using the database <b style=\"color:green\">vishal_abnave_borregaard_com_db</b>."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Using the database <b style=\"color:green\">vishal_abnave_borregaard_com_db</b>.",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mount \"/mnt/training\" again using \"%run \"./Includes/Dataset-Mounts-New\"\" if it is failed in \"./Includes/Classroom-Setup\"\n",
    "try:\n",
    "    files = dbutils.fs.ls(\"/mnt/training\")\n",
    "except:\n",
    "    dbutils.fs.unmount('/mnt/training/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8871cb41-a635-4106-882d-0586a09d2c2b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "All done!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run \"./Includes/Dataset-Mounts-New\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6569cc67-8f87-4ce3-9aec-c9faf3564d1a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Show Your Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7341e939-970e-49c9-bb40-89e046ea01ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(source, sasEntity, sasToken) = getAzureDataSource()\n",
    "spark.conf.set(sasEntity, sasToken)\n",
    "\n",
    "source = '/mnt/training'\n",
    "parquetDir = source + \"/wikipedia/pagecounts/staging_parquet_en_only_clean/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d200249c-f206-4e5f-86f5-643b6a7ab6f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Washingtons: 466\nTotal Washington Requests: 3,266\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "# Replace FILL_IN with your code. You will probably need multiple\n",
    "# lines of code for this problem.\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "washingtonsdf = (spark.read\n",
    "      .parquet(parquetDir)\n",
    "      .filter(col('project') == \"en\")\n",
    "      .filter(col('article').endswith('_Washington'))\n",
    "      # .filter( col(\"article\").like(\"%\\\\_Washington\") )\n",
    "     )\n",
    "\n",
    "washingtons = washingtonsdf.collect()\n",
    "\n",
    "totalWashingtons = 0\n",
    "\n",
    "for washington in washingtons:\n",
    "  totalWashingtons += washington[\"requests\"]\n",
    "  \n",
    "print(\"Total Washingtons: {0:,}\".format( len(washingtons) ))\n",
    "print(\"Total Washington Requests: {0:,}\".format( totalWashingtons ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eea6b7df-1a47-4eb0-8e12-08808389f26c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------------+--------+------------+\n|project|article                      |requests|bytes_served|\n+-------+-----------------------------+--------+------------+\n|en     |Adolphus_Washington          |1       |0           |\n|en     |Bangor_Base,_Washington      |3       |0           |\n|en     |Bellevue,_Washington         |17      |0           |\n|en     |Benton_County,_Washington    |1       |0           |\n|en     |Billy_Jack_Goes_to_Washington|2       |0           |\n+-------+-----------------------------+--------+------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "washingtonsdf.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ceb46f5a-e5f3-4322-8791-583506c6ee31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Marthas: 146\nTotal Martha Requests: 708\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "# Replace FILL_IN with your code. You will probably need multiple\n",
    "# lines of code for this problem.\n",
    "\n",
    "marthadf = (spark.read\n",
    "      .parquet(parquetDir)\n",
    "      .filter(col('project') == \"en\")\n",
    "      # .filter(col('article').startswith('Martha_'))\n",
    "      .filter( col(\"article\").like(\"Martha\\\\_%\") )\n",
    "     )\n",
    "\n",
    "marthas = marthadf.take(marthadf.count())\n",
    "\n",
    "totalMarthas = 0\n",
    "\n",
    "for martha in marthas:\n",
    "  totalMarthas += martha[\"requests\"]\n",
    "\n",
    "print(\"Total Marthas: {0:,}\".format( len(marthas) ))\n",
    "print(\"Total Martha Requests: {0:,}\".format( totalMarthas ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e16b23a5-073e-4881-a11d-a2aa9eab0549",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------------+--------+------------+\n|project|article                  |requests|bytes_served|\n+-------+-------------------------+--------+------------+\n|en     |Martha_Argerich          |13      |0           |\n|en     |Martha_Bunting           |1       |0           |\n|en     |Martha_Cecilia           |1       |0           |\n|en     |Martha_Coston            |1       |0           |\n|en     |Martha_Ellen_Young_Truman|6       |0           |\n+-------+-------------------------+--------+------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "marthadf.show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb9320b4-86a6-4134-bc59-edb75c1609a1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Verify Your Work\n",
    "Run the following cell to verify that your `DataFrame` was created properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21da1b49-1ccb-4562-9ccd-8d49a765c51b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Washingtons: 466\nTotal Washington Requests: 3,266\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Washingtons: {0:,}\".format( len(washingtons) ))\n",
    "print(\"Total Washington Requests: {0:,}\".format( totalWashingtons ))\n",
    "\n",
    "expectedCount = 466\n",
    "assert len(washingtons) == expectedCount, \"Expected \" + str(expectedCount) + \" articles but found \" + str( len(washingtons) )\n",
    "\n",
    "expectedTotal = 3266\n",
    "assert totalWashingtons == expectedTotal, \"Expected \" + str(expectedTotal) + \" requests but found \" + str(totalWashingtons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c71d43f-6282-4366-a318-951a152991c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Marthas: 146\nTotal Marthas Requests: 708\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Marthas: {0:,}\".format( len(marthas) ))\n",
    "print(\"Total Marthas Requests: {0:,}\".format( totalMarthas ))\n",
    "\n",
    "expectedCount = 146\n",
    "assert len(marthas) == expectedCount, \"Expected \" + str(expectedCount) + \" articles but found \" + str( len(marthas) )\n",
    "\n",
    "expectedTotal = 708\n",
    "assert totalMarthas == expectedTotal, \"Expected \" + str(expectedTotal) + \" requests but found \" + str(totalMarthas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ac68470-6082-46a6-8327-8fd0223adeb0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# My Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ee8349e-71f9-48f4-a274-08ef14fa9cb3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Washingtons: 466\nTotal Washington Requests: 3,266\nTotal Marthas: 146\nTotal Martha Requests: 708\n"
     ]
    }
   ],
   "source": [
    "totalWashingtons = (spark.read\n",
    "      .parquet(parquetDir)\n",
    "      .filter(col('project') == \"en\")\n",
    "      .filter(col('article').endswith('_Washington'))\n",
    "      .agg({'*' : 'count', 'requests' : 'sum'})\n",
    "      .collect()\n",
    "     )\n",
    "print(\"Total Washingtons: {0:,}\".format( totalWashingtons[0][0] ))\n",
    "print(\"Total Washington Requests: {0:,}\".format( totalWashingtons[0][1] ))\n",
    "\n",
    "\n",
    "totalMarthas = (spark.read\n",
    "      .parquet(parquetDir)\n",
    "      .filter(col('project') == \"en\")\n",
    "      .filter(col('article').startswith('Martha_'))\n",
    "      .agg({'*' : 'count', 'requests' : 'sum'})\n",
    "      .collect()\n",
    "     )\n",
    "print(\"Total Marthas: {0:,}\".format( totalMarthas[0][0] ))\n",
    "print(\"Total Martha Requests: {0:,}\".format( totalMarthas[0][1] ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9602478-2fc6-4bdb-9938-ec21ce702d16",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(count(1)=466, sum(requests)=3266)]\n[Row(count(1)=146, sum(requests)=708)]\n"
     ]
    }
   ],
   "source": [
    "print(totalWashingtons)\n",
    "print(totalMarthas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fea5bb2-e9da-4d28-9971-3913867998d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Washingtons: 466\nTotal Washingtons Requests: 3266\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "# BEST ANSWER - this is how you would do it in production\n",
    "\n",
    "from pyspark.sql.functions import *  # sum(), count()\n",
    "\n",
    "parquetDir = \"/mnt/training/wikipedia/pagecounts/staging_parquet_en_only_clean/\"\n",
    "\n",
    "stats = (spark.read\n",
    "  .parquet(parquetDir)\n",
    "  .filter((col(\"project\") == \"en\") & col(\"article\").endswith(\"_Washington\"))\n",
    "  .select(sum(\"requests\"), count(\"*\"))\n",
    "  .first())\n",
    "\n",
    "totalWashingtons = stats[0]\n",
    "washingtonCount = stats[1]\n",
    "\n",
    "print(\"Total Washingtons: {}\".format(washingtonCount) )\n",
    "print(\"Total Washingtons Requests: {}\".format(totalWashingtons))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3.Exercise-Washingtons-and-Marthas",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
